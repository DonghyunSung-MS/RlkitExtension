{
  "algorithm": "PPO",
  "algorithm_kwargs": {
    "batch_size": 256,
    "max_path_length": 1000,
    "min_num_steps_before_training": 1000,
    "num_epochs": 3,
    "num_eval_steps_per_epoch": 5000,
    "num_expl_steps_per_train_loop": 1000,
    "num_trains_per_train_loop": 1000
  },
  "layer_size": 256,
  "replay_buffer_size": 128,
  "trainer_kwargs": {
    "discount": 0.99,
    "policy_lr": 0.0003,
    "reward_scale": 1,
    "vf_lr": 0.0003
  },
  "version": "normal"
}